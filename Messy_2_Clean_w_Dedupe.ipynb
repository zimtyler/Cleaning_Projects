{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9939e59",
   "metadata": {},
   "source": [
    "# Cleaning mock client data\n",
    "\n",
    "For this notebook, I'll be showcasing some methods I use for cleaning messy data. While this dataset I created is not a standard financial report, it contains fields that I've found most likely to contain errors. Humans are prone to error, especially if the work is mundane and there are no data validation measures put in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "b7df59cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Client</th>\n",
       "      <th>Payment</th>\n",
       "      <th>Date_of_service</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alpha</td>\n",
       "      <td>$5,000</td>\n",
       "      <td>1/1/2022</td>\n",
       "      <td>Philadelphia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alpha</td>\n",
       "      <td>4000</td>\n",
       "      <td>Saturday, January 15, 2022</td>\n",
       "      <td>Philedelphia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alpha</td>\n",
       "      <td>4000</td>\n",
       "      <td>2/1/2022</td>\n",
       "      <td>Philaelphia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alfa</td>\n",
       "      <td>$5,000</td>\n",
       "      <td>3/15/2021</td>\n",
       "      <td>Philadelphia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lpha</td>\n",
       "      <td>$60,000,000.00</td>\n",
       "      <td>3/28/2022</td>\n",
       "      <td>Philadelphia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Client          Payment             Date_of_service      Location\n",
       "0   Alpha          $5,000                     1/1/2022  Philadelphia\n",
       "1   alpha             4000  Saturday, January 15, 2022  Philedelphia\n",
       "2  alpha              4000                    2/1/2022   Philaelphia\n",
       "3  Alfa            $5,000                    3/15/2021  Philadelphia\n",
       "4    lpha  $60,000,000.00                    3/28/2022  Philadelphia"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas_dedupe\n",
    "\n",
    "original_data = pd.read_csv('C:/Users/Tyler/Messy_CSV.csv')\n",
    "original_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44458b6",
   "metadata": {},
   "source": [
    "### .dedupe_dataframe() method\n",
    "In the first section, I'll be cleaning string data with the pandas_dedupe module.\n",
    "--For Windows users, we need to have Microsoft Visual C++ installed for the module to perform as it should--\n",
    "the pandas_dedupe module allows us to use Machine Learning to identify duplicate records that may have different spellings, trailing white spaces, different capitalization, etc.\n",
    "The .gazetteer_dataframe() method also allows for ML categorical matching to a canonical list, 'gazette', that contains the correct spelling for the strings in question.\n",
    "\n",
    "I already trained this model, but if its your first time, you will be prompted to answer (y)es, (n)o, (u)ncertain, (f)inish, and (p)revious to train the model yourself. Massive sets may take some training. See the [documentation](https://pypi.org/project/pandas-dedupe/) for more on how this module works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "85a7c35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing data ...\n",
      "Reading from dedupe_dataframe_learned_settings\n",
      "Clustering...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tyler\\anaconda3\\lib\\site-packages\\pandas_dedupe\\utility_functions.py:17: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df[i] = df[i].str.replace('[^\\w\\s\\.\\-\\(\\)\\,\\:\\/\\\\\\\\]','')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# duplicate sets 3\n",
      "      Client        Payment             Date_of_service      Location  \\\n",
      "0      alpha          5,000                    1/1/2022  philadelphia   \n",
      "1      alpha           4000  saturday, january 15, 2022  philedelphia   \n",
      "2      alpha           4000                    2/1/2022   philaelphia   \n",
      "3       alfa          5,000                   3/15/2021  philadelphia   \n",
      "4       lpha  60,000,000.00                   3/28/2022  philadelphia   \n",
      "5      alpha           5000                    4/1/2022  philadelphia   \n",
      "6      betha           4000                    1/2/2022      new york   \n",
      "7       beta            400                   1/16/2022      mew york   \n",
      "8      betha           5000                    2/2/2022      new york   \n",
      "9       beta          4,000                   2/16/2022       new yol   \n",
      "10    charly           5000                       3-jan            la   \n",
      "11   charley           5000                    3-feb-22          l.a.   \n",
      "12   charles          50000                    3/5/2022            la   \n",
      "13  chandler          5,000                   3/30/2022            la   \n",
      "\n",
      "    cluster id  confidence canonical_Client canonical_Payment  \\\n",
      "0            0    0.982236            alpha              5000   \n",
      "1            0    0.967265            alpha              5000   \n",
      "2            0    0.949863            alpha              5000   \n",
      "3            0    0.841560            alpha              5000   \n",
      "4            0    0.852083            alpha              5000   \n",
      "5            0    0.982236            alpha              5000   \n",
      "6            1    0.988379            betha              4000   \n",
      "7            1    0.989514            betha              4000   \n",
      "8            1    0.988379            betha              4000   \n",
      "9            1    0.986945            betha              4000   \n",
      "10           2    0.967325          charley             50000   \n",
      "11           2    0.724734          charley             50000   \n",
      "12           2    0.969648          charley             50000   \n",
      "13           2    0.725337          charley             50000   \n",
      "\n",
      "   canonical_Date_of_service canonical_Location  \n",
      "0                   1/1/2022       philadelphia  \n",
      "1                   1/1/2022       philadelphia  \n",
      "2                   1/1/2022       philadelphia  \n",
      "3                   1/1/2022       philadelphia  \n",
      "4                   1/1/2022       philadelphia  \n",
      "5                   1/1/2022       philadelphia  \n",
      "6                  1/16/2022           new york  \n",
      "7                  1/16/2022           new york  \n",
      "8                  1/16/2022           new york  \n",
      "9                  1/16/2022           new york  \n",
      "10                  3/5/2022                 la  \n",
      "11                  3/5/2022                 la  \n",
      "12                  3/5/2022                 la  \n",
      "13                  3/5/2022                 la  \n"
     ]
    }
   ],
   "source": [
    "df = pandas_dedupe.dedupe_dataframe( \n",
    "    original_data, \n",
    "    ['Client', 'Location'],\n",
    "    canonicalize=True,\n",
    "    )\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ad2583",
   "metadata": {},
   "source": [
    "Note that 'betha' was returned instead of 'beta'. Had I added more 'Beta' values to the original dataframe, the model would changed its canonical representation to the correct 'beta'. I decided to keep the incorrect 'betha' and use it to include some variation in my example for replacing values (charlie and los angeles) below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "4c2c58d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Client        Payment             Date_of_service      Location  \\\n",
      "0      alpha          5,000                    1/1/2022  philadelphia   \n",
      "1      alpha           4000  saturday, january 15, 2022  philedelphia   \n",
      "2      alpha           4000                    2/1/2022   philaelphia   \n",
      "3       alfa          5,000                   3/15/2021  philadelphia   \n",
      "4       lpha  60,000,000.00                   3/28/2022  philadelphia   \n",
      "5      alpha           5000                    4/1/2022  philadelphia   \n",
      "6      betha           4000                    1/2/2022      new york   \n",
      "7       beta            400                   1/16/2022      mew york   \n",
      "8      betha           5000                    2/2/2022      new york   \n",
      "9       beta          4,000                   2/16/2022       new yol   \n",
      "10    charly           5000                       3-jan            la   \n",
      "11   charley           5000                    3-feb-22          l.a.   \n",
      "12   charles          50000                    3/5/2022            la   \n",
      "13  chandler          5,000                   3/30/2022            la   \n",
      "\n",
      "    cluster id  confidence canonical_Client canonical_Payment  \\\n",
      "0            0    0.982236            alpha              5000   \n",
      "1            0    0.967265            alpha              5000   \n",
      "2            0    0.949863            alpha              5000   \n",
      "3            0    0.841560            alpha              5000   \n",
      "4            0    0.852083            alpha              5000   \n",
      "5            0    0.982236            alpha              5000   \n",
      "6            1    0.988379             beta              4000   \n",
      "7            1    0.989514             beta              4000   \n",
      "8            1    0.988379             beta              4000   \n",
      "9            1    0.986945             beta              4000   \n",
      "10           2    0.967325          charlie             50000   \n",
      "11           2    0.724734          charlie             50000   \n",
      "12           2    0.969648          charlie             50000   \n",
      "13           2    0.725337          charlie             50000   \n",
      "\n",
      "   canonical_Date_of_service canonical_Location  \n",
      "0                   1/1/2022       philadelphia  \n",
      "1                   1/1/2022       philadelphia  \n",
      "2                   1/1/2022       philadelphia  \n",
      "3                   1/1/2022       philadelphia  \n",
      "4                   1/1/2022       philadelphia  \n",
      "5                   1/1/2022       philadelphia  \n",
      "6                  1/16/2022           new york  \n",
      "7                  1/16/2022           new york  \n",
      "8                  1/16/2022           new york  \n",
      "9                  1/16/2022           new york  \n",
      "10                  3/5/2022        los angeles  \n",
      "11                  3/5/2022        los angeles  \n",
      "12                  3/5/2022        los angeles  \n",
      "13                  3/5/2022        los angeles  \n"
     ]
    }
   ],
   "source": [
    "df['canonical_Client'] = df['canonical_Client'].replace(to_replace=['betha', 'charley'], value=['beta', 'charlie'])\n",
    "df['canonical_Location'] = df['canonical_Location'].replace(to_replace='la', value='los angeles')\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cde85a",
   "metadata": {},
   "source": [
    "### Replacing the messy strings with the clean strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "9ee19889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Client          Payment             Date_of_service      Location\n",
      "0     alpha          $5,000                     1/1/2022  philadelphia\n",
      "1     alpha             4000  Saturday, January 15, 2022  philadelphia\n",
      "2     alpha             4000                    2/1/2022  philadelphia\n",
      "3     alpha          $5,000                    3/15/2021  philadelphia\n",
      "4     alpha  $60,000,000.00                    3/28/2022  philadelphia\n",
      "5     alpha             5000                    4/1/2022  philadelphia\n",
      "6      beta             4000                    1/2/2022      new york\n",
      "7      beta              400                   1/16/2022      new york\n",
      "8      beta             5000                    2/2/2022      new york\n",
      "9      beta          $4,000                    2/16/2022      new york\n",
      "10  charlie             5000                       3-Jan   los angeles\n",
      "11  charlie             5000                    3-Feb-22   los angeles\n",
      "12  charlie            50000                    3/5/2022   los angeles\n",
      "13  charlie          $5,000                    3/30/2022   los angeles\n"
     ]
    }
   ],
   "source": [
    "original_data[['Client', 'Location']] = df[['canonical_Client', 'canonical_Location']]\n",
    "print(original_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a542360e",
   "metadata": {},
   "source": [
    "### Alright, time to clean up some numbers\n",
    "Here's a basic function that I use for cleaning unwanted characters from my data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "f3ac4c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         5000\n",
       "1         4000\n",
       "2         4000\n",
       "3         5000\n",
       "4     60000000\n",
       "5         5000\n",
       "6         4000\n",
       "7          400\n",
       "8         5000\n",
       "9         4000\n",
       "10        5000\n",
       "11        5000\n",
       "12       50000\n",
       "13        5000\n",
       "Name: Payment, dtype: object"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of characters to remove\n",
    "chars_to_remove = ['.00', ',', '$', ' ']\n",
    "\n",
    "for character in chars_to_remove:\n",
    "    # Replace the character with an empty string\n",
    "    original_data['Payment'] = original_data['Payment'].apply(lambda x: x.replace(character, ''))\n",
    "        \n",
    "original_data['Payment']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5d745f",
   "metadata": {},
   "source": [
    "In this fictional case, I imagine that all the payments are in the thousands. In the real world, that isn't so simple. Unfortunately, we may have to refer to a different table or pull up an invoice to find the correct value.\n",
    "\n",
    "But for fun, I put some unnecessary constraints to see what I could do.\n",
    "\n",
    "By transforming the data type into a string, I was able to quickly remove any 0s with regular expressions and then convert it back to integer and multiply by 1000. I really don't see when I would have to do this, but it was fun nonetheless. It also shows off the left to right processing of stacked methods/transformations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "3ad4fd7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Client  Payment             Date_of_service      Location\n",
      "0     alpha     5000                    1/1/2022  philadelphia\n",
      "1     alpha     4000  Saturday, January 15, 2022  philadelphia\n",
      "2     alpha     4000                    2/1/2022  philadelphia\n",
      "3     alpha     5000                   3/15/2021  philadelphia\n",
      "4     alpha     6000                   3/28/2022  philadelphia\n",
      "5     alpha     5000                    4/1/2022  philadelphia\n",
      "6      beta     4000                    1/2/2022      new york\n",
      "7      beta     4000                   1/16/2022      new york\n",
      "8      beta     5000                    2/2/2022      new york\n",
      "9      beta     4000                   2/16/2022      new york\n",
      "10  charlie     5000                       3-Jan   los angeles\n",
      "11  charlie     5000                    3-Feb-22   los angeles\n",
      "12  charlie     5000                    3/5/2022   los angeles\n",
      "13  charlie     5000                   3/30/2022   los angeles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tyler\\AppData\\Local\\Temp/ipykernel_2644/1218524444.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  original_data['Payment'] = original_data['Payment'].astype('str').str.replace(r'(0+)', '').astype('int')*1000\n"
     ]
    }
   ],
   "source": [
    "original_data['Payment'] = original_data['Payment'].astype('str').str.replace(r'(0+)', '').astype('int')*1000\n",
    "print(original_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa08fb6",
   "metadata": {},
   "source": [
    "### Now lets clean up some incorret date formats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "7a821c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Client  Payment Date_of_service      Location\n",
      "0     alpha     5000      2022-01-01  philadelphia\n",
      "1     alpha     4000      2022-01-15  philadelphia\n",
      "2     alpha     4000      2022-02-01  philadelphia\n",
      "3     alpha     5000      2021-03-15  philadelphia\n",
      "4     alpha     6000      2022-03-28  philadelphia\n",
      "5     alpha     5000      2022-04-01  philadelphia\n",
      "6      beta     4000      2022-01-02      new york\n",
      "7      beta     4000      2022-01-16      new york\n",
      "8      beta     5000      2022-02-02      new york\n",
      "9      beta     4000      2022-02-16      new york\n",
      "10  charlie     5000             NaT   los angeles\n",
      "11  charlie     5000      2022-02-03   los angeles\n",
      "12  charlie     5000      2022-03-05   los angeles\n",
      "13  charlie     5000      2022-03-30   los angeles\n"
     ]
    }
   ],
   "source": [
    "original_data['Date_of_service'] = pd.to_datetime(original_data['Date_of_service'], errors = 'coerce')\n",
    "\n",
    "print(original_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833accf2",
   "metadata": {},
   "source": [
    "After having to coerce the .to_datetime function, we need to look for missing values in the Date_of_service column and fix them.\n",
    "\n",
    "As we can see below, we only have one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "ecf657e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Client</th>\n",
       "      <th>Payment</th>\n",
       "      <th>Date_of_service</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>charlie</td>\n",
       "      <td>5000</td>\n",
       "      <td>NaT</td>\n",
       "      <td>los angeles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Client  Payment Date_of_service     Location\n",
       "10  charlie     5000             NaT  los angeles"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data[original_data['Date_of_service'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed635145",
   "metadata": {},
   "source": [
    "We would probably need to reference an invoice or different table to find the date of service for this value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "7dae4a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Client  Payment Date_of_service      Location\n",
      "0     alpha     5000      2022-01-01  philadelphia\n",
      "1     alpha     4000      2022-01-15  philadelphia\n",
      "2     alpha     4000      2022-02-01  philadelphia\n",
      "3     alpha     5000      2021-03-15  philadelphia\n",
      "4     alpha     6000      2022-03-28  philadelphia\n",
      "5     alpha     5000      2022-04-01  philadelphia\n",
      "6      beta     4000      2022-01-02      new york\n",
      "7      beta     4000      2022-01-16      new york\n",
      "8      beta     5000      2022-02-02      new york\n",
      "9      beta     4000      2022-02-16      new york\n",
      "10  charlie     5000      2022-01-03   los angeles\n",
      "11  charlie     5000      2022-02-03   los angeles\n",
      "12  charlie     5000      2022-03-05   los angeles\n",
      "13  charlie     5000      2022-03-30   los angeles\n"
     ]
    }
   ],
   "source": [
    "original_data.loc[10,['Date_of_service']] = pd.to_datetime('2022-01-03')\n",
    "print(original_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafed440",
   "metadata": {},
   "source": [
    "Lets make sure that all the dates are in 2022.\n",
    "\n",
    "We can clearly see there is one, but larger data might contain more errors (due to manual entry, loading error, transformation error, etc). To find if there are any dates that aren't within 2022, I'll first save a series of boolean values and then use a list comprehension to find the index for the dates outside of 2022.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "a7c15235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Client  Payment Date_of_service      Location\n",
      "0     alpha     5000      2022-01-01  philadelphia\n",
      "1     alpha     4000      2022-01-15  philadelphia\n",
      "2     alpha     4000      2022-02-01  philadelphia\n",
      "3     alpha     5000      2022-01-01  philadelphia\n",
      "4     alpha     6000      2022-03-28  philadelphia\n",
      "5     alpha     5000      2022-04-01  philadelphia\n",
      "6      beta     4000      2022-01-02      new york\n",
      "7      beta     4000      2022-01-16      new york\n",
      "8      beta     5000      2022-02-02      new york\n",
      "9      beta     4000      2022-02-16      new york\n",
      "10  charlie     5000      2022-01-03   los angeles\n",
      "11  charlie     5000      2022-02-03   los angeles\n",
      "12  charlie     5000      2022-03-05   los angeles\n",
      "13  charlie     5000      2022-03-30   los angeles\n"
     ]
    }
   ],
   "source": [
    "mislabeled_years = (original_data['Date_of_service'] < '2022-01-01') | (original_data['Date_of_service'] > '2022-12-31')\n",
    "mislabeled_dates_index = [i for i, x in enumerate(mislabeled_years) if x]\n",
    "original_data.loc[mislabeled_dates_index, ['Date_of_service']] = pd.to_datetime('2022')\n",
    "print(original_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "5cbacf1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Client  Payment Date_of_service      Location\n",
      "0     Alpha     5000      2022-01-01  Philadelphia\n",
      "1     Alpha     4000      2022-01-15  Philadelphia\n",
      "2     Alpha     4000      2022-02-01  Philadelphia\n",
      "3     Alpha     5000      2022-01-01  Philadelphia\n",
      "4     Alpha     6000      2022-03-28  Philadelphia\n",
      "5     Alpha     5000      2022-04-01  Philadelphia\n",
      "6      Beta     4000      2022-01-02      New York\n",
      "7      Beta     4000      2022-01-16      New York\n",
      "8      Beta     5000      2022-02-02      New York\n",
      "9      Beta     4000      2022-02-16      New York\n",
      "10  Charlie     5000      2022-01-03   Los Angeles\n",
      "11  Charlie     5000      2022-02-03   Los Angeles\n",
      "12  Charlie     5000      2022-03-05   Los Angeles\n",
      "13  Charlie     5000      2022-03-30   Los Angeles\n"
     ]
    }
   ],
   "source": [
    "original_data['Client'] = original_data['Client'].str.capitalize() #Capitalizing the appropriate strings (if needed)\n",
    "original_data['Location'] = original_data['Location'].str.title()\n",
    "\n",
    "print(original_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "4825d762",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.to_csv('Clean_CSV.csv') #Saving the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa61dd05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
